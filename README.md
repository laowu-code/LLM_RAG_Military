# 基于LLM的军事策略的RAG系统构建
## 给定设定的军事对抗场景输出相应的军事策略。利用Langchain框架构建基于Qwen2-7B-instruct的RAG军事策略系统，利用Faiss向量库对PDF和TXT格式数据进行向量化存储，对query在向量库中进行相似化搜索返回top k相关文档片段作为context与query一起送入LLM中，同时对上下文构建检索支链以实现对话记忆，最终实现对应军事策略输出，并通过streamlit构建WebUI进行人机对话交互。
## 环境配置
## 必要核心库：
### transformers==4.42.4
### torch==2.3.0+cu121
### torchvision==0.18.0+cu121
### faiss-gpu==1.7.2
### sentence-transformers==3.0.1
### langchain==0.2.11
### langchain-community==0.2.10
### langchain-core==0.2.24
### langchain-huggingface==0.0.3
### streamlit==1.24.0
### tqdm==4.66.4
### numpy==1.26.3
### python==3.10
### 主要根据Qwen2_RAG.py文件中的导入库进行配置。
## 目录说明
### 本项目目录结构旨在为军事策略生成系统提供一个有序且高效的文件管理方案。以下是对各目录及文件的详细说明，以确保用户能够清晰理解每个部分的功能和作用：
### 论文数据：该目录收录了大量与军事策略相关的学术论文和文献。这些资料为系统提供了丰富的背景知识，有助于提升策略生成的深度和广度。
### data_pdf：此路径专门用于存储知识库的原始文件，包括PDF和TXT格式的文档。这些文件是系统进行信息检索和数据挖掘的基础，确保了策略生成的原始数据来源。
### embeddings：该目录用于存放向量编码模型。选择合适的向量编码模型对于提高文档检索的准确性至关重要。建议选用对中文语料友好的编码模型，以优化系统性能。
### faiss_index：在此目录中存储了向量化后的文档索引。使用Faiss库构建的索引能够高效地处理高维向量数据，加速相似文档的检索过程。
### qwen：该目录存放了大型语言模型（LLM），即Qwen2-7B-instruct。选择适合的LLM对于生成高质量的军事策略至关重要。需要注意的是，不同LLM的参数规模和兼容性可能有所不同，因此在选择时要考虑与Langchain架构的兼容性。国产LLM都需要重新封装接口，重写基本调用函数。重写方法参考Qwen2_RAG.py中的Qwen()类。
### Model_Qwen2-7B-instruct：包含Jupyter格式的LoRA微调框架。该框架用于对选定的LLM进行微调，以更好地适应特定的军事策略生成任务。该文件未测试，需要重新根据需求编写。
### Qwen2_RAG_copy.py：该文件是RAG系统的前几个迭代版本的副本。它记录了系统开发过程中的关键步骤和变更，对于追踪项目进展和复现实验结果具有重要价值。
### Qwen2_RAG.py：这是RAG系统的主运行文件，代码中的函数请仔细阅读注释
。通过运行最后一行注释指示的命令，可以在指定的地址和端口启动Streamlit服务器，进而与用户进行交互。运行代码为：streamlit run Qwen2_RAG.py --server.address 127.0.0.1 --server.port 6006.
### requirements.txt：该文件包含了项目环境所需的所有库及其版本信息。它确保了开发环境的一致性，如果上述环境配置有误，请查询该文件。
### split_docs.pkl：存储了经过分割处理的文本数据。文本分割是提高文档处理效率和检索准确性的重要步骤，该文件确保了系统能够高效地处理大量文档。
### 通过上述目录结构和文件说明，用户可以更好地理解每个组件的作用，以及它们如何协同工作以支持军事策略生成系统的整体功能。这种清晰的组织结构不仅有助于项目的维护和扩展，也便于新用户的学习和参与。

