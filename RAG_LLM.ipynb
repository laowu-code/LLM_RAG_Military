{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a68486d0-c987-44f1-9f11-a2d7652940e9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96902763-767a-4a28-be04-9269f79f7fc7",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# 预先下载并保存嵌入模型\n",
    "embedding_model_name = \"all-MiniLM-L6-v2\"\n",
    "embedding_model = SentenceTransformer(embedding_model_name)\n",
    "embedding_model.save(\"model_embedding\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf4a75c-7cad-4355-acb8-1f73824df807",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9d063bda-6d3d-4170-90bd-408e6b0b24e5",
   "metadata": {
    "tags": []
   },
   "source": [
    "# RAG with Langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1430a4ed-e534-45aa-866c-97cc4b929acc",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-07-31T08:00:47.420830Z",
     "iopub.status.busy": "2024-07-31T08:00:47.420330Z",
     "iopub.status.idle": "2024-07-31T08:00:47.465018Z",
     "shell.execute_reply": "2024-07-31T08:00:47.464209Z",
     "shell.execute_reply.started": "2024-07-31T08:00:47.420799Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'SimpleDirectoryLoader' from 'langchain.document_loaders' (/usr/local/lib/python3.10/site-packages/langchain/document_loaders/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHF_ENDPOINT\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://hf-mirror.com\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mfitz\u001b[39;00m  \u001b[38;5;66;03m# PyMuPDF\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdocument_loaders\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SimpleDirectoryLoader\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtext_splitter\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RecursiveCharacterTextSplitter\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01membeddings\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HuggingFaceEmbeddings\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'SimpleDirectoryLoader' from 'langchain.document_loaders' (/usr/local/lib/python3.10/site-packages/langchain/document_loaders/__init__.py)"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"HF_ENDPOINT\"] = \"https://hf-mirror.com\"\n",
    "import fitz  # PyMuPDF\n",
    "from langchain.document_loaders import SimpleDirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# 指定PDF文件目录\n",
    "pdf_dir = \"data_pdf\"\n",
    "\n",
    "# 提取PDF文本\n",
    "def extract_text_from_pdfs(pdf_dir):\n",
    "    texts = []\n",
    "    for pdf_file in os.listdir(pdf_dir):\n",
    "        if pdf_file.endswith(\".pdf\"):\n",
    "            pdf_path = os.path.join(pdf_dir, pdf_file)\n",
    "            doc = fitz.open(pdf_path)\n",
    "            text = \"\"\n",
    "            for page in doc:\n",
    "                text += page.get_text()\n",
    "            texts.append(text)\n",
    "    return texts\n",
    "\n",
    "# 加载PDF文本\n",
    "texts = extract_text_from_pdfs(pdf_dir)\n",
    "\n",
    "# 切分文本\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "docs = text_splitter.create_documents(texts)\n",
    "\n",
    "embedding_model =HuggingFaceEmbeddings(\"model_embedding/all-MiniLM-L6-v2\")\n",
    "\n",
    "# model =\n",
    "\n",
    "# 生成嵌入向量并存储在FAISS向量数据库中\n",
    "vector_store = FAISS.from_documents(docs, embedding_model)\n",
    "vector_store.save_local(\"faiss_index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e4bf02-05a5-4ff7-8ce4-9356f2103b0c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "# 加载Qwen2-7B模型和分词器\n",
    "model_name = \"qwen/autodl-tmp/qwen/Qwen2-7B-Instruct/\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "\n",
    "from langchain.chains import RetrievalAugmentedGenerationChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.llms import TransformersLLM\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "# 加载FAISS向量数据库\n",
    "vector_store = FAISS.load_local(\"faiss_index\", embedding_model)\n",
    "\n",
    "# 定义Prompt模板\n",
    "prompt_template = PromptTemplate(\n",
    "    input_variables=[\"context\", \"question\"],\n",
    "    template=\"基于以下内容回答问题：\\n\\n{context}\\n\\n问题：{question}\\n答案：\"\n",
    ")\n",
    "\n",
    "# 定义检索器\n",
    "retriever = vector_store.as_retriever()\n",
    "\n",
    "# 创建LLM对象\n",
    "llm = TransformersLLM(model=model, tokenizer=tokenizer)\n",
    "\n",
    "# 创建RAG链\n",
    "rag_chain = RetrievalAugmentedGenerationChain(\n",
    "    llm=llm,\n",
    "    retriever=retriever,\n",
    "    prompt_template=prompt_template,\n",
    "    memory=ConversationBufferMemory()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c427dd4-32af-4cef-a029-f43fb2d757e2",
   "metadata": {},
   "source": [
    "\n",
    " - [ ] _list1_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b60e3d3e-3789-4a74-ab2f-3ffcba7959d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
